# LLM Fine-tuning Repository

This repository contains various implementations of Large Language Model (LLM) fine-tuning using different models and techniques. Each notebook demonstrates a specific use case and fine-tuning approach.

## Notebooks Overview

### 1. Gemma LoRA Fine-tuning
- **File**: `Fine tune_LLM_Gemma_lora.ipynb`
- **Description**: Implementation of fine-tuning Google's Gemma model using LoRA (Low-Rank Adaptation) technique.
- **Model**: Google's Gemma (2B/7B parameters)
- **Use Case**: General purpose fine-tuning with parameter-efficient approach
- **Key Features**:
  - LoRA implementation for efficient fine-tuning
  - Reduced memory footprint
  - Faster training times
  - Maintains model performance

### 2. T5-Small Text Summarization
- **File**: `Fine tune_LLM_T5-small(Text_Summarizing).ipynb`
- **Description**: Fine-tuning T5-small model for text summarization tasks.
- **Model**: T5-Small (60M parameters)
- **Use Case**: Text summarization and compression
- **Key Features**:
  - Sequence-to-sequence architecture
  - Abstractive summarization capabilities
  - Lightweight model suitable for deployment
  - Customizable summary length

### 3. Llama 2 Chatbot
- **File**: `Fine tune_LLM_Llama_2(chat bot).ipynb`
- **Description**: Implementation of a chatbot using fine-tuned Llama 2 model.
- **Model**: Llama 2 (7B/13B/70B parameters)
- **Use Case**: Conversational AI and chatbot development
- **Key Features**:
  - Instruction fine-tuning
  - Chat completion capabilities
  - Context-aware responses
  - Safety and alignment features

### 4. Mistral-7B QLoRA Auto Reply System
- **File**: `Fine tune_LLM_Mistral-7B_qlora(auto reply system).ipynb`
- **Description**: Fine-tuning Mistral-7B model using QLoRA (Quantized LoRA) for an automated reply system.
- **Model**: Mistral-7B
- **Use Case**: Automated response generation
- **Key Features**:
  - 4-bit quantization
  - Memory-efficient training
  - High-quality response generation
  - Reduced computational requirements

### 5. Sentiment Analysis with LoRA
- **File**: 
  - `Fine tune LLM with LoRA for sentiment analysis_v1.ipynb`
  - `Fine tune LLM with LoRA for sentiment analysis_v2.ipynb`
- **Description**: Two versions of sentiment analysis implementation using LoRA fine-tuning technique.
- **Model**: Various base models
- **Use Case**: Text sentiment classification
- **Key Features**:
  - Binary and multi-class sentiment analysis
  - Efficient fine-tuning with LoRA
  - Improved version with enhanced accuracy
  - Real-time inference capabilities

## Dataset
The repository includes a `Dataset` directory containing the training data used for fine-tuning various models. Each notebook uses specific datasets:

### 1. Gemma LoRA Fine-tuning
- **Dataset**: [Alpaca Dataset](https://github.com/tatsu-lab/stanford_alpaca)
- **Description**: 52K instruction-following demonstrations
- **Format**: JSON with instruction, input, and output fields
- **Use Case**: General instruction fine-tuning

### 2. T5-Small Text Summarization
- **Dataset**: [CNN/DailyMail Dataset](https://huggingface.co/datasets/cnn_dailymail)
- **Description**: News articles with human-written summaries
- **Size**: 300K+ article-summary pairs
- **Format**: Article text and corresponding summaries

### 3. Llama 2 Chatbot
- **Dataset**: [ShareGPT Dataset](https://huggingface.co/datasets/AlekseyKorshuk/reasoning-tasks)
- **Description**: High-quality human-AI conversations
- **Format**: Conversation pairs with human and AI turns
- **Use Case**: Chatbot training and instruction following

### 4. Mistral-7B QLoRA Auto Reply System
- **Dataset**: [Alpaca-GPT4 Dataset](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM)
- **Description**: 52K instruction-following examples generated by GPT-4
- **Format**: Instruction-response pairs
- **Use Case**: Automated response generation

### 5. Sentiment Analysis with LoRA
- **Dataset**: 
  - [IMDB Dataset](https://huggingface.co/datasets/imdb)
  - [SST-2 Dataset](https://huggingface.co/datasets/glue/viewer/sst2)
- **Description**: 
  - IMDB: 50K movie reviews with binary sentiment labels
  - SST-2: 67K sentences with sentiment annotations
- **Format**: Text with sentiment labels
- **Use Case**: Binary and multi-class sentiment analysis

### Additional Resources
- [Hugging Face Datasets](https://huggingface.co/datasets) - For accessing and downloading datasets
- [Papers With Code](https://paperswithcode.com/datasets) - For finding benchmark datasets
- [Kaggle Datasets](https://www.kaggle.com/datasets) - For additional training data

## Requirements
To run these notebooks, you'll need:
- Python 3.8+
- PyTorch (2.0.0 or higher)
- Transformers library (4.30.0 or higher)
- PEFT (Parameter-Efficient Fine-Tuning)
- CUDA-compatible GPU (recommended)
- Minimum 16GB RAM
- 50GB+ free disk space
- CUDA Toolkit 11.7 or higher

## Installation
```bash
# Create a virtual environment
python -m venv llm-finetune-env
source llm-finetune-env/bin/activate  # On Windows: llm-finetune-env\Scripts\activate

# Install dependencies
pip install torch transformers peft datasets accelerate bitsandbytes
pip install jupyter notebook
```

## Getting Started
1. Clone this repository
2. Install the required dependencies
3. Choose the notebook that matches your use case
4. Follow the instructions in the notebook to fine-tune your model
5. Monitor training progress and metrics
6. Evaluate model performance
7. Deploy the fine-tuned model

## Fine-tuning Techniques Used
- LoRA (Low-Rank Adaptation)
  - Reduces trainable parameters
  - Maintains model performance
  - Faster training times
- QLoRA (Quantized LoRA)
  - 4-bit quantization
  - Memory-efficient training
  - Suitable for large models
- Full fine-tuning (where applicable)
  - Complete model parameter updates
  - Maximum performance potential
  - Higher resource requirements

## Model Evaluation
Each implementation includes:
- Performance metrics
- Evaluation datasets
- Comparison with baseline models
- Error analysis
- Inference examples

## Best Practices
- Use appropriate batch sizes for your GPU
- Monitor memory usage during training
- Save checkpoints regularly
- Validate model outputs
- Test on diverse inputs
- Consider ethical implications

## Note
Each notebook contains detailed comments and explanations of the fine-tuning process. Make sure to read through the notebook before running it to understand the specific requirements and setup needed for each implementation.

## Contributing
Contributions are welcome! Please feel free to submit a Pull Request.

## License
This project is licensed under the MIT License - see the LICENSE file for details. 